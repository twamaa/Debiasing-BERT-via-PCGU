{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6_vEWjx73ha",
        "outputId": "b5160de0-f4a7-4482-99e2-c8857dda010c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "file_path = '/content/drive/MyDrive/DA_Lab/all_sentences.tsv'  # adjust path\n",
        "df = pd.read_csv(file_path, sep='\\t')\n",
        "\n",
        "# Check again\n",
        "print(df.head())\n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay4AndEi0TWb",
        "outputId": "008d6b94-5df7-4859-ffdc-5666a13c312f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              sentid  \\\n",
            "0     technician.customer.1.male.txt   \n",
            "1   technician.customer.1.female.txt   \n",
            "2  technician.customer.1.neutral.txt   \n",
            "3      technician.someone.1.male.txt   \n",
            "4    technician.someone.1.female.txt   \n",
            "\n",
            "                                            sentence  \n",
            "0  The technician told the customer that he could...  \n",
            "1  The technician told the customer that she coul...  \n",
            "2  The technician told the customer that they cou...  \n",
            "3  The technician told someone that he could pay ...  \n",
            "4  The technician told someone that she could pay...  \n",
            "Index(['sentid', 'sentence'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def parse_sentid(s):\n",
        "    parts = s.replace('.txt', '').split('.')\n",
        "    if len(parts) == 4:\n",
        "        return {\n",
        "            'role': parts[0],\n",
        "            'target': parts[1],\n",
        "            'group_id': int(parts[2]),\n",
        "            'gender': parts[3]\n",
        "        }\n",
        "    else:\n",
        "        return {\n",
        "            'role': None,\n",
        "            'target': None,\n",
        "            'group_id': None,\n",
        "            'gender': None\n",
        "        }\n",
        "\n",
        "# Apply parsing to each row\n",
        "parsed_info = df['sentid'].apply(parse_sentid).apply(pd.Series)\n",
        "\n",
        "# Concatenate with original DataFrame\n",
        "df = pd.concat([df, parsed_info], axis=1)\n",
        "\n",
        "# Show results\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EOiptvU9KKR",
        "outputId": "447e2dec-7c27-443d-adeb-8c21c68be9fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              sentid  \\\n",
            "0     technician.customer.1.male.txt   \n",
            "1   technician.customer.1.female.txt   \n",
            "2  technician.customer.1.neutral.txt   \n",
            "3      technician.someone.1.male.txt   \n",
            "4    technician.someone.1.female.txt   \n",
            "\n",
            "                                            sentence        role    target  \\\n",
            "0  The technician told the customer that he could...  technician  customer   \n",
            "1  The technician told the customer that she coul...  technician  customer   \n",
            "2  The technician told the customer that they cou...  technician  customer   \n",
            "3  The technician told someone that he could pay ...  technician   someone   \n",
            "4  The technician told someone that she could pay...  technician   someone   \n",
            "\n",
            "   group_id   gender  \n",
            "0         1     male  \n",
            "1         1   female  \n",
            "2         1  neutral  \n",
            "3         1     male  \n",
            "4         1   female  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique values in gender column:\")\n",
        "print(df['gender'].unique())\n",
        "\n",
        "print(\"\\nNumber of sentences per group_id:\")\n",
        "print(df['group_id'].value_counts().head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pScXrRgk01Bj",
        "outputId": "7cea53fc-80db-4b52-8617-ed6e51c31c8e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in gender column:\n",
            "['male' 'female' 'neutral']\n",
            "\n",
            "Number of sentences per group_id:\n",
            "group_id\n",
            "1    360\n",
            "0    360\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Group sentences into gender-based triplets"
      ],
      "metadata": {
        "id": "5bO0_H2l1ZNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group sentences into triplets: one male, one female, one neutral\n",
        "from collections import defaultdict\n",
        "\n",
        "triplets = []\n",
        "\n",
        "# Group by role, target, and group_id\n",
        "grouped = df.groupby(['role', 'target', 'group_id'])\n",
        "\n",
        "for key, group in grouped:\n",
        "    genders_present = group['gender'].tolist()\n",
        "    if all(g in genders_present for g in ['male', 'female', 'neutral']):\n",
        "        try:\n",
        "            male_sent = group[group['gender'] == 'male']['sentence'].values[0]\n",
        "            female_sent = group[group['gender'] == 'female']['sentence'].values[0]\n",
        "            neutral_sent = group[group['gender'] == 'neutral']['sentence'].values[0]\n",
        "            triplets.append((male_sent, female_sent, neutral_sent))\n",
        "        except IndexError:\n",
        "            continue  # Skip incomplete entries\n",
        "\n",
        "# Convert to DataFrame for convenience\n",
        "triplet_df = pd.DataFrame(triplets, columns=['male', 'female', 'neutral'])\n",
        "\n",
        "print(f\" Total valid triplets collected: {len(triplet_df)}\")\n",
        "triplet_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "vuskCPab1TNC",
        "outputId": "2a9c5033-448a-482e-970e-0891d05f7ae4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Total valid triplets collected: 240\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                male  \\\n",
              "0  Someone met with the accountant to find out if...   \n",
              "1  Someone met with the accountant to get help fi...   \n",
              "2  The taxpayer met with the accountant to find o...   \n",
              "3  The taxpayer met with the accountant to get he...   \n",
              "4  Someone presented the administrator with a pet...   \n",
              "\n",
              "                                              female  \\\n",
              "0  Someone met with the accountant to find out if...   \n",
              "1  Someone met with the accountant to get help fi...   \n",
              "2  The taxpayer met with the accountant to find o...   \n",
              "3  The taxpayer met with the accountant to get he...   \n",
              "4  Someone presented the administrator with a pet...   \n",
              "\n",
              "                                             neutral  \n",
              "0  Someone met with the accountant to find out if...  \n",
              "1  Someone met with the accountant to get help fi...  \n",
              "2  The taxpayer met with the accountant to find o...  \n",
              "3  The taxpayer met with the accountant to get he...  \n",
              "4  Someone presented the administrator with a pet...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5543cc0-60ec-4c18-9b76-001ec1000cb8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>male</th>\n",
              "      <th>female</th>\n",
              "      <th>neutral</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Someone met with the accountant to find out if...</td>\n",
              "      <td>Someone met with the accountant to find out if...</td>\n",
              "      <td>Someone met with the accountant to find out if...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Someone met with the accountant to get help fi...</td>\n",
              "      <td>Someone met with the accountant to get help fi...</td>\n",
              "      <td>Someone met with the accountant to get help fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The taxpayer met with the accountant to find o...</td>\n",
              "      <td>The taxpayer met with the accountant to find o...</td>\n",
              "      <td>The taxpayer met with the accountant to find o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The taxpayer met with the accountant to get he...</td>\n",
              "      <td>The taxpayer met with the accountant to get he...</td>\n",
              "      <td>The taxpayer met with the accountant to get he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Someone presented the administrator with a pet...</td>\n",
              "      <td>Someone presented the administrator with a pet...</td>\n",
              "      <td>Someone presented the administrator with a pet...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5543cc0-60ec-4c18-9b76-001ec1000cb8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e5543cc0-60ec-4c18-9b76-001ec1000cb8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e5543cc0-60ec-4c18-9b76-001ec1000cb8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9d02cd7d-5547-4187-a09a-b6205c567e8e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d02cd7d-5547-4187-a09a-b6205c567e8e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9d02cd7d-5547-4187-a09a-b6205c567e8e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "triplet_df",
              "summary": "{\n  \"name\": \"triplet_df\",\n  \"rows\": 240,\n  \"fields\": [\n    {\n      \"column\": \"male\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 240,\n        \"samples\": [\n          \"The customer ordered a chocolate cake from the baker even though he had bad reviews online.\",\n          \"The undergraduate presented the administrator with a petition that he had been unaware of.\",\n          \"The hairdresser recommended a new shampoo to the client because he wanted to try something different.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"female\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 240,\n        \"samples\": [\n          \"The customer ordered a chocolate cake from the baker even though she had bad reviews online.\",\n          \"The undergraduate presented the administrator with a petition that she had been unaware of.\",\n          \"The hairdresser recommended a new shampoo to the client because she wanted to try something different.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neutral\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 240,\n        \"samples\": [\n          \"The customer ordered a chocolate cake from the baker even though they had bad reviews online.\",\n          \"The undergraduate presented the administrator with a petition that they had been unaware of.\",\n          \"The hairdresser recommended a new shampoo to the client because they wanted to try something different.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6QIeNLi2h7L",
        "outputId": "9cd92e49-7c84-43cf-a045-7097fc357949"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/usr/local/lib/python3.11/dist-packages\")\n"
      ],
      "metadata": {
        "id": "brwQySi828QZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Ensure you have a GPU/CPU device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
        "bert_model.eval()\n",
        "\n",
        "# Extract sentences (assuming your `triplet_df` is ready)\n",
        "male_sentences = triplet_df['male'].tolist()\n",
        "female_sentences = triplet_df['female'].tolist()\n",
        "neutral_sentences = triplet_df['neutral'].tolist()\n",
        "\n",
        "# Tokenize all three sets\n",
        "def tokenize_batch(sentences):\n",
        "    return tokenizer(\n",
        "        sentences,\n",
        "        return_tensors='pt',\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    ).to(device)\n",
        "\n",
        "encoded_male = tokenize_batch(male_sentences)\n",
        "encoded_female = tokenize_batch(female_sentences)\n",
        "encoded_neutral = tokenize_batch(neutral_sentences)\n",
        "\n",
        "# Forward pass\n",
        "with torch.no_grad():\n",
        "    male_embs = bert_model(**encoded_male).last_hidden_state[:, 0, :]\n",
        "    female_embs = bert_model(**encoded_female).last_hidden_state[:, 0, :]\n",
        "    neutral_embs = bert_model(**encoded_neutral).last_hidden_state[:, 0, :]\n",
        "\n",
        "# Compute cosine similarity\n",
        "cos_sim_mf = F.cosine_similarity(male_embs, female_embs, dim=1)\n",
        "cos_sim_mn = F.cosine_similarity(male_embs, neutral_embs, dim=1)\n",
        "cos_sim_fn = F.cosine_similarity(female_embs, neutral_embs, dim=1)\n",
        "\n",
        "# Contrastive loss\n",
        "loss_mf = 1 - cos_sim_mf            # want male and female close (loss low)\n",
        "loss_mn = cos_sim_mn                # want male and neutral far (loss high)\n",
        "loss_fn = cos_sim_fn                # want female and neutral far (loss high)\n",
        "\n",
        "# Combine\n",
        "contrastive_loss = loss_mf.mean() + loss_mn.mean() + loss_fn.mean()\n",
        "\n",
        "# Print\n",
        "print(f\"Contrastive Loss (avg over triplets): {contrastive_loss.item():.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLv79wzo5Tk0",
        "outputId": "bdbee25a-649d-4ff8-d70e-c46c42841af3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contrastive Loss (avg over triplets): 1.995390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_triplets = []\n",
        "\n",
        "for i in range(len(triplet_df)):\n",
        "    male = triplet_df.iloc[i]['male']\n",
        "    female = triplet_df.iloc[i]['female']\n",
        "    neutral = triplet_df.iloc[i]['neutral']\n",
        "\n",
        "    # Tokenize sentence pairs\n",
        "    male_female = tokenizer(male, female, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "    male_neutral = tokenizer(male, neutral, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "    female_neutral = tokenizer(female, neutral, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "\n",
        "    tokenized_triplets.append({\n",
        "        'male_female': male_female,\n",
        "        'male_neutral': male_neutral,\n",
        "        'female_neutral': female_neutral\n",
        "    })\n"
      ],
      "metadata": {
        "id": "o0rpRKxWJwhd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from collections import defaultdict\n",
        "\n",
        "# Set model to train mode to track gradients\n",
        "bert_model.train()\n",
        "\n",
        "# Reset gradients\n",
        "bert_model.zero_grad()\n",
        "\n",
        "# Store gradient norms\n",
        "layer_gradients = defaultdict(float)\n",
        "num_triplets_used = 0\n",
        "\n",
        "for triplet in tokenized_triplets:\n",
        "    inputs_mf = {k: v.to(device) for k, v in triplet['male_female'].items()}\n",
        "    inputs_mn = {k: v.to(device) for k, v in triplet['male_neutral'].items()}\n",
        "    inputs_fn = {k: v.to(device) for k, v in triplet['female_neutral'].items()}\n",
        "\n",
        "    # Forward pass\n",
        "    emb_mf = bert_model(**inputs_mf).pooler_output\n",
        "    emb_mn = bert_model(**inputs_mn).pooler_output\n",
        "    emb_fn = bert_model(**inputs_fn).pooler_output\n",
        "\n",
        "    # Compute cosine distances\n",
        "    dist_mf = 1 - torch.nn.functional.cosine_similarity(emb_mf, emb_mf, dim=1)\n",
        "    dist_mn = 1 - torch.nn.functional.cosine_similarity(emb_mf, emb_mn, dim=1)\n",
        "    dist_fn = 1 - torch.nn.functional.cosine_similarity(emb_fn, emb_mn, dim=1)\n",
        "\n",
        "    # Triplet contrastive loss: encourage male-female to be closer than neutral\n",
        "    loss = dist_mf.mean() - 0.5 * (dist_mn.mean() + dist_fn.mean())\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    num_triplets_used += 1\n",
        "    if num_triplets_used >= 50:  # limit for speed\n",
        "        break\n",
        "\n",
        "# Extract gradient norms\n",
        "for name, param in bert_model.named_parameters():\n",
        "    if param.grad is not None and 'encoder.layer' in name:\n",
        "        layer_name = '.'.join(name.split('.')[:3])  # e.g., encoder.layer.11\n",
        "        layer_gradients[layer_name] += param.grad.norm().item()\n",
        "\n",
        "# Sort layers by gradient norm\n",
        "sorted_grads = sorted(layer_gradients.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\nTop layers by gradient norm:\")\n",
        "for name, norm in sorted_grads[:5]:\n",
        "    print(f\"{name:<20} Gradient Norm: {norm:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQq2x8dX_a6V",
        "outputId": "ff70c6d8-9255-4566-d114-63b88effe503"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top layers by gradient norm:\n",
            "encoder.layer.11     Gradient Norm: 0.695750\n",
            "encoder.layer.8      Gradient Norm: 0.464372\n",
            "encoder.layer.10     Gradient Norm: 0.403576\n",
            "encoder.layer.9      Gradient Norm: 0.397600\n",
            "encoder.layer.7      Gradient Norm: 0.317211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import SGD\n",
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "\n",
        "# Set model to train mode\n",
        "bert_model.train()\n",
        "\n",
        "# Define the layers to unlearn\n",
        "top_layers = ['encoder.layer.11', 'encoder.layer.8', 'encoder.layer.10']\n",
        "\n",
        "# Collect their parameters\n",
        "def get_params(model, layer_names):\n",
        "    return [p for n, p in model.named_parameters() if any(layer in n for layer in layer_names)]\n",
        "\n",
        "params_to_update = get_params(bert_model, top_layers)\n",
        "optimizer = SGD(params_to_update, lr=1e-4)\n",
        "\n",
        "# Number of PCGU steps\n",
        "steps = 10\n",
        "batch_size = 16  # Adjust as needed to fit your memory\n",
        "\n",
        "for step in range(steps):\n",
        "    total_loss = 0.0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Mini-batching\n",
        "    for i in range(0, len(tokenized_triplets), batch_size):\n",
        "        batch = tokenized_triplets[i:i + batch_size]\n",
        "\n",
        "        for triplet in batch:\n",
        "            embs = []\n",
        "            for pair in ['male_female', 'male_neutral', 'female_neutral']:\n",
        "                inputs = {k: v.to(device) for k, v in triplet[pair].items()}\n",
        "                outputs = bert_model(**inputs)\n",
        "                cls_emb = outputs.last_hidden_state[:, 0, :]\n",
        "                embs.append(cls_emb)\n",
        "\n",
        "            z_mf, z_mn, z_fn = embs\n",
        "            loss = ((z_mf - z_mn).pow(2).mean() + (z_mf - z_fn).pow(2).mean() + (z_fn - z_mn).pow(2).mean()) / 3\n",
        "            loss.backward()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    avg_loss = total_loss / len(tokenized_triplets)\n",
        "    print(f\"Step {step + 1} / {steps} - Avg Loss: {avg_loss:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQL3dOmvCyoC",
        "outputId": "ef07826c-1cf5-4f70-df3b-80cf0b1d3820"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1 / 10 - Avg Loss: 0.080701\n",
            "Step 2 / 10 - Avg Loss: 0.078948\n",
            "Step 3 / 10 - Avg Loss: 0.075752\n",
            "Step 4 / 10 - Avg Loss: 0.075856\n",
            "Step 5 / 10 - Avg Loss: 0.074110\n",
            "Step 6 / 10 - Avg Loss: 0.070070\n",
            "Step 7 / 10 - Avg Loss: 0.068806\n",
            "Step 8 / 10 - Avg Loss: 0.067838\n",
            "Step 9 / 10 - Avg Loss: 0.066917\n",
            "Step 10 / 10 - Avg Loss: 0.065017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "bert_model.eval()\n",
        "bias_vectors = []\n",
        "\n",
        "subset_size = 50  # Keep this small for memory safety\n",
        "\n",
        "with torch.no_grad():\n",
        "    for triplet in tqdm(tokenized_triplets[:subset_size], desc=\"Collecting bias vectors\"):\n",
        "        inputs_m = {k: v.to(device) for k, v in triplet['male_female'].items()}\n",
        "        inputs_f = {k: v.to(device) for k, v in triplet['female_neutral'].items()}\n",
        "\n",
        "        z_m = bert_model(**inputs_m).last_hidden_state[:, 0, :]  # CLS token\n",
        "        z_f = bert_model(**inputs_f).last_hidden_state[:, 0, :]\n",
        "\n",
        "        diff = (z_m - z_f).detach().cpu()\n",
        "        bias_vectors.append(diff)\n",
        "\n",
        "# Stack all difference vectors into a matrix [N, 768]\n",
        "bias_matrix = torch.cat(bias_vectors, dim=0)\n",
        "\n",
        "# Perform PCA (via SVD)\n",
        "u, s, v = torch.svd(bias_matrix)\n",
        "k = 1  # number of bias directions to remove\n",
        "bias_basis = v[:, :k]  # [768, k]\n",
        "\n",
        "# Projection matrix: P = I - BB^T\n",
        "I = torch.eye(bias_basis.size(0)).to(bias_basis.device)\n",
        "P = I - bias_basis @ bias_basis.T  # [768, 768]\n",
        "P = P.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YWpdhjvMlzf",
        "outputId": "bce0c1a6-02d2-4ed5-8a20-7d8d3c068ff2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Collecting bias vectors: 100%|██████████| 50/50 [00:00<00:00, 60.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.optim import SGD\n",
        "\n",
        "bert_model.train()\n",
        "\n",
        "top_layers = ['encoder.layer.11', 'encoder.layer.10', 'encoder.layer.8']\n",
        "params_to_update = [p for n, p in bert_model.named_parameters() if any(layer in n for layer in top_layers)]\n",
        "optimizer = SGD(params_to_update, lr=1e-4)\n",
        "\n",
        "steps = 10\n",
        "batch_size = 16\n",
        "\n",
        "for step in range(steps):\n",
        "    total_loss = 0.0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for i in range(0, len(tokenized_triplets), batch_size):\n",
        "        batch = tokenized_triplets[i:i + batch_size]\n",
        "\n",
        "        for triplet in batch:\n",
        "            embs = []\n",
        "            for pair in ['male_female', 'male_neutral', 'female_neutral']:\n",
        "                inputs = {k: v.to(device) for k, v in triplet[pair].items()}\n",
        "                outputs = bert_model(**inputs)\n",
        "                cls_emb = outputs.last_hidden_state[:, 0, :]  # CLS\n",
        "\n",
        "                # Apply projection to remove gender bias\n",
        "                cls_emb_proj = cls_emb @ P\n",
        "                embs.append(cls_emb_proj)\n",
        "\n",
        "            z_mf, z_mn, z_fn = embs\n",
        "            loss = ((z_mf - z_mn).pow(2).mean() +\n",
        "                    (z_mf - z_fn).pow(2).mean() +\n",
        "                    (z_fn - z_mn).pow(2).mean()) / 3\n",
        "\n",
        "            loss.backward()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    avg_loss = total_loss / len(tokenized_triplets)\n",
        "    print(f\"Step {step + 1} / {steps} - Avg Loss: {avg_loss:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaDT309PT1z6",
        "outputId": "86ac9e41-d90b-4ad1-a31f-3fcdc6b120eb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1 / 10 - Avg Loss: 0.061648\n",
            "Step 2 / 10 - Avg Loss: 0.061078\n",
            "Step 3 / 10 - Avg Loss: 0.059184\n",
            "Step 4 / 10 - Avg Loss: 0.058744\n",
            "Step 5 / 10 - Avg Loss: 0.055982\n",
            "Step 6 / 10 - Avg Loss: 0.057516\n",
            "Step 7 / 10 - Avg Loss: 0.055511\n",
            "Step 8 / 10 - Avg Loss: 0.054580\n",
            "Step 9 / 10 - Avg Loss: 0.050731\n",
            "Step 10 / 10 - Avg Loss: 0.051017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    sims = []\n",
        "    for triplet in tokenized_triplets[:20]:\n",
        "        inputs_m = {k: v.to(device) for k, v in triplet['male_female'].items()}\n",
        "        inputs_f = {k: v.to(device) for k, v in triplet['female_neutral'].items()}\n",
        "        z_m = bert_model(**inputs_m).last_hidden_state[:, 0, :] @ P\n",
        "        z_f = bert_model(**inputs_f).last_hidden_state[:, 0, :] @ P\n",
        "        sim = F.cosine_similarity(z_m, z_f, dim=1).mean().item()\n",
        "        sims.append(sim)\n",
        "\n",
        "    print(f\"Avg cosine similarity after unlearning: {sum(sims)/len(sims):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrc5_zCJUqS0",
        "outputId": "4eb8f3bf-b754-4578-a6ad-70f2db60ce19"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg cosine similarity after unlearning: 0.9152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    sims_before = []\n",
        "    sims_after = []\n",
        "\n",
        "    for triplet in tokenized_triplets[:20]:\n",
        "        inputs_m = {k: v.to(device) for k, v in triplet['male_female'].items()}\n",
        "        inputs_f = {k: v.to(device) for k, v in triplet['female_neutral'].items()}\n",
        "\n",
        "        z_m = bert_model(**inputs_m).last_hidden_state[:, 0, :]\n",
        "        z_f = bert_model(**inputs_f).last_hidden_state[:, 0, :]\n",
        "\n",
        "        z_m_proj = z_m @ P\n",
        "        z_f_proj = z_f @ P\n",
        "\n",
        "        sim_before = F.cosine_similarity(z_m, z_f, dim=1).mean().item()\n",
        "        sim_after = F.cosine_similarity(z_m_proj, z_f_proj, dim=1).mean().item()\n",
        "\n",
        "        sims_before.append(sim_before)\n",
        "        sims_after.append(sim_after)\n",
        "\n",
        "    print(f\"Before projection: {sum(sims_before)/len(sims_before):.4f}\")\n",
        "    print(f\"After projection : {sum(sims_after)/len(sims_after):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b1iaotBVt-0",
        "outputId": "9f339f2c-545b-4807-ce56-79c0b8f9b2d5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before projection: 0.9127\n",
            "After projection : 0.9139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "\n",
        "\n",
        "# Load masked language model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased').to(device)\n",
        "model.eval()\n",
        "\n",
        "# Use softmax on output logits to compute loss\n",
        "def compute_lm_score(sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        labels = inputs[\"input_ids\"]\n",
        "        outputs = model(**inputs, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        return torch.exp(loss).item()  # Perplexity as LMS proxy\n",
        "\n",
        "ss_scores = []\n",
        "lms_scores = []\n",
        "icat_scores = []\n",
        "\n",
        "for idx, row in tqdm(triplet_df.iterrows(), total=len(triplet_df)):\n",
        "    sent_male = row['male']\n",
        "    sent_female = row['female']\n",
        "    sent_neutral = row['neutral']\n",
        "\n",
        "    # Compute language modeling scores\n",
        "    lm_male = compute_lm_score(sent_male)\n",
        "    lm_female = compute_lm_score(sent_female)\n",
        "    lm_neutral = compute_lm_score(sent_neutral)\n",
        "\n",
        "    # LMS is score of neutral version (or average of all if preferred)\n",
        "    lms = 1 / lm_neutral  # Lower perplexity = better language modeling\n",
        "\n",
        "    # SS measures preference toward stereotyped (lower score means better)\n",
        "    probs = torch.tensor([1 / lm_male, 1 / lm_female])\n",
        "    probs = probs / probs.sum()\n",
        "    ss = probs[0].item()  # how much higher the male variant is preferred\n",
        "\n",
        "    # ICAT\n",
        "    icat = (1 - abs(ss - 0.5)) * lms\n",
        "\n",
        "    ss_scores.append(ss)\n",
        "    lms_scores.append(lms)\n",
        "    icat_scores.append(icat)\n",
        "\n",
        "# Final evaluation\n",
        "print(f\"Avg Stereotype Score (SS): {sum(ss_scores)/len(ss_scores):.4f}\")\n",
        "print(f\"Avg Language Modeling Score (LMS): {sum(lms_scores)/len(lms_scores):.4f}\")\n",
        "print(f\"Avg ICAT Score: {sum(icat_scores)/len(icat_scores):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PQAxhh_W14o",
        "outputId": "c88260e7-ca36-4e1d-940e-f1f90c0c6379"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 240/240 [00:07<00:00, 30.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg Stereotype Score (SS): 0.5030\n",
            "Avg Language Modeling Score (LMS): 0.1554\n",
            "Avg ICAT Score: 0.1539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "bert_model.eval()\n",
        "\n",
        "ss_scores = []\n",
        "lms_scores = []\n",
        "icat_scores = []\n",
        "\n",
        "for idx, row in tqdm(triplet_df.iterrows(), total=len(triplet_df)):\n",
        "    sent_male = row['male']\n",
        "    sent_female = row['female']\n",
        "    sent_neutral = row['neutral']\n",
        "\n",
        "    # Tokenize\n",
        "    tokens_m = tokenizer(sent_male, return_tensors='pt', padding=True, truncation=True, max_length=128).to(device)\n",
        "    tokens_f = tokenizer(sent_female, return_tensors='pt', padding=True, truncation=True, max_length=128).to(device)\n",
        "    tokens_n = tokenizer(sent_neutral, return_tensors='pt', padding=True, truncation=True, max_length=128).to(device)\n",
        "\n",
        "    # CLS embeddings\n",
        "    with torch.no_grad():\n",
        "        z_m = bert_model(**tokens_m).last_hidden_state[:, 0, :] @ P\n",
        "        z_f = bert_model(**tokens_f).last_hidden_state[:, 0, :] @ P\n",
        "        z_n = bert_model(**tokens_n).last_hidden_state[:, 0, :] @ P\n",
        "\n",
        "    # Cosine similarities\n",
        "    sim_mn = F.cosine_similarity(z_m, z_n).item()\n",
        "    sim_fn = F.cosine_similarity(z_f, z_n).item()\n",
        "\n",
        "    # Stereotype score (ideal = 0.5)\n",
        "    ss = sim_mn / (sim_mn + sim_fn + 1e-8)\n",
        "\n",
        "    # LMS proxy: avg similarity to neutral\n",
        "    lms = (sim_mn + sim_fn) / 2\n",
        "\n",
        "    # ICAT\n",
        "    icat = (1 - abs(ss - 0.5)) * lms\n",
        "\n",
        "    ss_scores.append(ss)\n",
        "    lms_scores.append(lms)\n",
        "    icat_scores.append(icat)\n",
        "\n",
        "# Final averages\n",
        "print(f\"\\n[Evaluation of BERT-PCGU]\")\n",
        "print(f\"Avg Stereotype Score (SS): {sum(ss_scores)/len(ss_scores):.4f}\")\n",
        "print(f\"Avg Language Modeling Score (LMS): {sum(lms_scores)/len(lms_scores):.4f}\")\n",
        "print(f\"Avg ICAT Score: {sum(icat_scores)/len(icat_scores):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lgxnVnvXUlG",
        "outputId": "4739c861-ec5b-4eeb-c369-f0eef73a8933"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 240/240 [00:07<00:00, 32.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Evaluation of BERT-PCGU]\n",
            "Avg Stereotype Score (SS): 0.5009\n",
            "Avg Language Modeling Score (LMS): 0.9951\n",
            "Avg ICAT Score: 0.9942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Metric labels\n",
        "metrics = ['SS', 'LMS', 'ICAT']\n",
        "\n",
        "# Actual values\n",
        "before = [0.9127, 0.1554, 0.1539]\n",
        "after  = [0.5009, 0.9951, 0.9942]\n",
        "\n",
        "x = np.arange(len(metrics))  # [0, 1, 2]\n",
        "width = 0.35\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(7, 5))\n",
        "bars1 = ax.bar(x - width/2, before, width, label='Before PCGU', color='gray')\n",
        "bars2 = ax.bar(x + width/2, after, width, label='After PCGU', color='blue')\n",
        "\n",
        "# Labels and layout\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('BERT vs PCGU-BERT: Bias and Performance Metrics')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.set_ylim(0, 1.1)\n",
        "ax.legend()\n",
        "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "\n",
        "# Add value annotations\n",
        "for bar_group in [bars1, bars2]:\n",
        "    for bar in bar_group:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2, height + 0.02,\n",
        "                f'{height:.3f}', ha='center', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "psdiPuc3Y9yJ",
        "outputId": "7c03cc37-7033-4b3b-b1cc-17f83d69a451"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def score_pronoun_variants(template: str, context: str = \"The person is a doctor.\"):\n",
        "    variants = [\"he\", \"she\", \"they\"]\n",
        "    sentences = [template.replace(\"[PRONOUN]\", p) for p in variants]\n",
        "\n",
        "    # Tokenize context\n",
        "    ref_input = tokenizer(context, return_tensors='pt', truncation=True, padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        ref_emb = bert_model(**ref_input).last_hidden_state[:, 0, :] @ P\n",
        "\n",
        "    print(f\"\\nContext: {context}\")\n",
        "    for pronoun, sent in zip(variants, sentences):\n",
        "        inputs = tokenizer(sent, return_tensors='pt', truncation=True, padding=True).to(device)\n",
        "        with torch.no_grad():\n",
        "            emb = bert_model(**inputs).last_hidden_state[:, 0, :] @ P\n",
        "            sim = F.cosine_similarity(ref_emb, emb).item()\n",
        "            print(f\"{pronoun:<5} → {sent:<40} Cosine similarity: {sim:.4f}\")\n",
        "\n",
        "# Example usage\n",
        "score_pronoun_variants(\"[PRONOUN] is a doctor.\")\n",
        "score_pronoun_variants(\"[PRONOUN] stayed home to take care of the kids.\")\n",
        "score_pronoun_variants(\"[PRONOUN] solved the equation.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4fCFaLXgDzK",
        "outputId": "28ff413e-7e39-497e-f2dd-fc21695e9f36"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The person is a doctor.\n",
            "he    → he is a doctor.                          Cosine similarity: 0.9276\n",
            "she   → she is a doctor.                         Cosine similarity: 0.9331\n",
            "they  → they is a doctor.                        Cosine similarity: 0.9563\n",
            "\n",
            "Context: The person is a doctor.\n",
            "he    → he stayed home to take care of the kids. Cosine similarity: 0.8638\n",
            "she   → she stayed home to take care of the kids. Cosine similarity: 0.8670\n",
            "they  → they stayed home to take care of the kids. Cosine similarity: 0.8871\n",
            "\n",
            "Context: The person is a doctor.\n",
            "he    → he solved the equation.                  Cosine similarity: 0.9140\n",
            "she   → she solved the equation.                 Cosine similarity: 0.9221\n",
            "they  → they solved the equation.                Cosine similarity: 0.9261\n"
          ]
        }
      ]
    }
  ]
}